"""Tavily integration ‚Äî primary research substrate for market data.

Fetches market size, growth rates, CAGR, and adoption trend paragraphs
using Tavily's advanced search. Returns clean text passages only.
"""

from __future__ import annotations

import asyncio
import os
import re
import logging
from typing import List, Dict, Any

import httpx

# ---------------------------------------------------------------------------
# Tavily API configuration
# ---------------------------------------------------------------------------
_TAVILY_API_URL = "https://api.tavily.com/search"
_REQUEST_TIMEOUT = 15.0  # seconds
_MAX_RESULTS_PER_QUERY = 5


def _get_tavily_key() -> str:
    """Read the Tavily API key from the environment."""
    key = os.getenv("TAVILY_API_KEY", "").strip()
    if not key:
        print("‚ö†Ô∏è  [TAVILY] API key missing (TAVILY_API_KEY)")
        raise EnvironmentError("TAVILY_API_KEY environment variable not set")
    return key


def _clean_passage(text: str) -> str:
    """Remove ads, navigation fragments, and collapse whitespace."""
    # Strip common boilerplate patterns
    text = re.sub(r"(Subscribe|Sign up|Log in|Cookie|Advertisement)[\s\S]{0,80}", "", text, flags=re.IGNORECASE)
    # Collapse whitespace
    text = re.sub(r"\s+", " ", text).strip()
    return text


def _has_numeric_signals(text: str) -> bool:
    """Return True if text contains market-relevant numeric data.

    Looks for: dollar amounts, percentages, billions/millions, CAGR,
    year references (2020-2030), or large numbers with commas.
    """
    patterns = [
        r"\$[\d,.]+",           # Dollar amounts
        r"\d+(\.\d+)?%",        # Percentages
        r"\d+(\.\d+)?\s*(billion|million|trillion|bn|mn|B|M|T)\b",  # Revenue figures
        r"CAGR",                # Compound annual growth rate
        r"20[12]\d",            # Year references 2010-2029
        r"\d{1,3}(,\d{3})+",   # Large numbers with commas
    ]
    for pattern in patterns:
        if re.search(pattern, text, re.IGNORECASE):
            return True
    return False


def _build_queries(
    *,
    industry: str,
    one_line_description: str,
    geography: str,
    startup_name: str,
    target_customer_type: str = "",
) -> list[str]:
    """Build numeric-seeking Tavily queries for market research.

    Uses all available input fields: industry, one_line_description,
    geography, target_customer_type. Each query targets passages
    with revenue figures, CAGR, market size in USD, company counts.

    NOT for competitors (that's Exa's job).
    """
    geo_suffix = f" in {geography}" if geography and geography.lower() != "global" else ""
    customer = (target_customer_type or "").strip()
    desc = (one_line_description or "").strip()

    queries = [
        # Market size query ‚Äî anchored on industry + geography
        f"market size of {industry}{geo_suffix} revenue USD 2024 2025",
        # Growth rate query ‚Äî CAGR focused
        f"growth rate of {industry} market CAGR last 5 years",
        # Description-aware query ‚Äî surfaces problem-specific market data
        f"{desc} market size revenue{geo_suffix}" if desc else f"{industry} market report annual revenue forecast billion",
        # Customer-aware query ‚Äî targets spending data for the customer type
        f"{customer} spending on {industry} solutions{geo_suffix}" if customer else f"number of companies operating in {industry} market{geo_suffix}",
        # Pain & friction query ‚Äî cost of current workflows
        f"cost of {industry} inefficiency for {customer}{geo_suffix}" if customer else f"{industry} market inefficiency cost",
    ]
    return queries


async def _search_tavily(api_key: str, query: str) -> List[Dict[str, Any]]:
    """Execute a single Tavily search (async) and return result dicts."""
    payload = {
        "api_key": api_key,
        "query": query,
        "search_depth": "advanced",
        "max_results": _MAX_RESULTS_PER_QUERY,
        "include_answer": False,
    }
    try:
        async with httpx.AsyncClient(timeout=_REQUEST_TIMEOUT) as client:
            response = await client.post(_TAVILY_API_URL, json=payload)
        if response.status_code == 200:
            data = response.json()
            results = data.get("results", [])
            print(f"\U0001f4e6 [MR] Tavily: {len(results)} results for {query!r}")
            return results
        else:
            print(f"\u26a0\ufe0f [MR] Tavily HTTP {response.status_code} for {query!r}")
            return []
    except httpx.TimeoutException:
        print(f"\u26a0\ufe0f [MR] Tavily timeout for {query!r}")
        return []
    except Exception as exc:
        print(f"\u274c [MR] Tavily error for {query!r}: {exc}")
        return []


async def fetch_market_research_text(query_bundle: dict) -> list[str]:
    """Fetch market research passages via Tavily advanced search.

    Parameters
    ----------
    query_bundle : dict
        Must contain: industry, one_line_description, geography, startup_name

    Returns
    -------
    list[str]
        Clean research passages. Empty list if Tavily fails or key is missing.
    """
    print("üîç [TAVILY] Querying market size & growth")

    try:
        api_key = _get_tavily_key()
    except EnvironmentError:
        print("‚ö†Ô∏è  [TAVILY] Skipping ‚Äî no API key. Agent will continue with low confidence.")
        return []

    queries = _build_queries(
        industry=query_bundle["industry"],
        one_line_description=query_bundle["one_line_description"],
        geography=query_bundle["geography"],
        startup_name=query_bundle["startup_name"],
        target_customer_type=query_bundle.get("target_customer_type", ""),
    )

    all_passages: list[str] = []
    seen_urls: set[str] = set()
    numeric_passage_count = 0

    # Run all Tavily queries in parallel
    tasks = [_search_tavily(api_key, q) for q in queries]
    query_results = await asyncio.gather(*tasks, return_exceptions=True)

    for query_result in query_results:
        if isinstance(query_result, Exception):
            continue
        for result in query_result:
            url = result.get("url", "")
            if url in seen_urls:
                continue
            seen_urls.add(url)

            content = result.get("content", "")
            if not content or len(content) < 50:
                continue

            cleaned = _clean_passage(content)
            if len(cleaned) >= 50:
                all_passages.append(cleaned)
                # Check if passage contains numeric anchors
                if _has_numeric_signals(cleaned):
                    numeric_passage_count += 1

    total = len(all_passages)
    print(f"‚úÖ [TAVILY] Retrieved {total} research passages")
    print(f"üìä [TAVILY] Passages with numeric data: {numeric_passage_count}/{total}")
    if total > 0 and numeric_passage_count == 0:
        print("‚ö†Ô∏è  [TAVILY] No passages contain numeric market data ‚Äî signal is WEAK")
    return all_passages
